{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "130ba72e-5a6f-47d0-832e-7c501f2e3310",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Agent notebook\n",
    "\n",
    "This is very similar to an auto-generated notebook created by an AI Playground export. There are three notebooks in the same folder:\n",
    "- [**agent**]($./agent): contains the code to build the agent.\n",
    "\n",
    "This notebook uses Mosaic AI Agent Framework ([AWS](https://docs.databricks.com/en/generative-ai/retrieval-augmented-generation.html) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/generative-ai/retrieval-augmented-generation)) to create your agent. It defines a LangChain agent that has access to tools, which we define in this notebook as well.\n",
    "\n",
    "Use this notebook to iterate on and modify the agent. For example, you could add more tools or change the system prompt.\n",
    "\n",
    " **_NOTE:_**  This notebook uses LangChain, however AI Agent Framework is compatible with other agent frameworks like Pyfunc and LlamaIndex.\n",
    "\n",
    "## Next steps\n",
    "\n",
    "After testing and iterating on your agent in this notebook, go to the auto-generated [agent-eval-deployment]($./agent-eval-deployment) notebook in this folder to log, register, evaluate, and deploy the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9931f427-d2f3-42d6-ac0a-7618119bb3dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade databricks-agents unitycatalog-ai[databricks] unitycatalog-langchain[databricks] databricks-langchain databricks-vectorsearch==0.56 langchain==0.3.20 langgraph==0.3.4 pydantic==2.11.7 mlflow[databricks]\n",
    "#langchain-community langgraph langgraph-checkpoint langchain_core==0.3.67\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fae38785-f976-4d7d-9a6e-132a4d8f2773",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Define the chat model and tools\n",
    "Create a LangChain chat model that supports [LangGraph tool](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/) calling.\n",
    "\n",
    "We'll be importing tools from UC as well as defining a retriever. See [LangChain - How to create tools](https://python.langchain.com/v0.2/docs/how_to/custom_tools/) and [LangChain - Using built-in tools](https://python.langchain.com/v0.2/docs/how_to/tools_builtin/).\n",
    "\n",
    " **_NOTE:_**  This notebook uses LangChain, however AI Agent Framework is compatible with other agent frameworks like Pyfunc and LlamaIndex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "466c6cac-c0b7-410d-a4f7-5750b29a184d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Define Retriever Tool\n",
    "\n",
    "We'll use the vector retreival tool in conjunction with a Unity Catalog function, to enrich the output with some additional data that the agent will use downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2c2fade-44cc-48a0-addf-308580ff86ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from databricks_langchain.vectorstores import DatabricksVectorSearch\n",
    "from langchain_community.tools.databricks import UCFunctionToolkit\n",
    "import mlflow\n",
    "from mlflow.models import ModelConfig\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "CATALOG = 'media_advertising'\n",
    "SCHEMA = 'contextual_advertising'\n",
    "\n",
    "vs_endpoint = 'one-env-shared-endpoint-10'\n",
    "index_name = f'{CATALOG}.{SCHEMA}.movie_scripts_content_vs'\n",
    "\n",
    "# Specify the return type schema of our retriever, so that evaluation and UIs can\n",
    "# automatically display retrieved chunks\n",
    "mlflow.models.set_retriever_schema(\n",
    "    primary_key=\"unique_movie_scene_id\",\n",
    "    text_column=\"scene_text\",\n",
    "    other_columns=[\"title\", \"scene_number\"],\n",
    "    name= index_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION media_advertising.contextual_advertising.search_movie_scripts (\n",
    "  -- The agent uses this comment to determine how to generate the query string parameter.\n",
    "  query STRING\n",
    "  COMMENT 'The query string for searching the movie script database'\n",
    ") RETURNS TABLE\n",
    "-- The agent uses this comment to determine when to call this tool. It describes the types of documents and information contained within the index.\n",
    "COMMENT 'Search for relevant script chunks from the movie scripts database that matches the intent of the user request including elements of the scene that would make it a good fit' RETURN\n",
    "SELECT\n",
    "  scene_text as page_content,\n",
    "  map('title', TRY_CAST(title AS STRING), 'scene_number', TRY_CAST(scene_number AS STRING), 'search_score', TRY_CAST(search_score AS STRING)) as metadata\n",
    "FROM\n",
    "  vector_search(\n",
    "    -- Specify your Vector Search index name here\n",
    "    index => 'media_advertising.contextual_advertising.movie_scripts_content_vs',\n",
    "    query_text => query,\n",
    "    query_type => \"hybrid\",\n",
    "    num_results => 5\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70fed967-5418-4d5c-854f-f12ea01851bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create the agent\n",
    "Here we provide a simple graph that uses the model and tools defined by [config.yml]($./config.yml). This graph is adapated from [this LangGraph guide](https://langchain-ai.github.io/langgraph/how-tos/react-agent-from-scratch/).\n",
    "\n",
    "\n",
    "To further customize your LangGraph agent, you can refer to:\n",
    "* [LangGraph - Quick Start](https://langchain-ai.github.io/langgraph/tutorials/introduction/) for explanations of the concepts used in this LangGraph agent\n",
    "* [LangGraph - How-to Guides](https://langchain-ai.github.io/langgraph/how-tos/) to expand the functionality of your agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbf0dc5b-2fd9-4316-b3ca-e9b6f38898a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile agent.py\n",
    "import json\n",
    "from typing import (\n",
    "    Any,\n",
    "    Annotated,\n",
    "    Optional,\n",
    "    Generator,\n",
    "    Sequence,\n",
    "    TypedDict,\n",
    "    Union,\n",
    ")\n",
    "from uuid import uuid4\n",
    "\n",
    "import mlflow\n",
    "from databricks_langchain import ChatDatabricks\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    AIMessageChunk,\n",
    "    BaseMessage,\n",
    "    convert_to_openai_messages,\n",
    ")\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langchain_core.tools import BaseTool\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.graph import CompiledGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from langgraph.graph.message import add_messages\n",
    "from mlflow.pyfunc import ResponsesAgent\n",
    "from mlflow.types.responses import (\n",
    "    ResponsesAgentRequest,\n",
    "    ResponsesAgentResponse,\n",
    "    ResponsesAgentStreamEvent,\n",
    ")\n",
    "from unitycatalog.ai.langchain.toolkit import UCFunctionToolkit\n",
    "\n",
    "# --- Setup LLM and tools ---\n",
    "function_name = \"media_advertising.contextual_advertising.search_movie_scripts\"\n",
    "toolkit = UCFunctionToolkit(\n",
    "    function_names=[\n",
    "        function_name\n",
    "    ]\n",
    ")\n",
    "tools = toolkit.tools\n",
    "llm_endpoint = \"databricks-claude-sonnet-4\"\n",
    "\n",
    "index_name = f'media_advertising.contextual_advertising.movie_scripts_content_vs'\n",
    "llm = ChatDatabricks(endpoint=llm_endpoint)\n",
    "\n",
    "# --- Agent Graph Definition ---\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    custom_inputs: Optional[dict[str, Any]]\n",
    "    custom_outputs: Optional[dict[str, Any]]\n",
    "\n",
    "def create_tool_calling_agent(\n",
    "    model: LanguageModelLike,\n",
    "    tools: Union[ToolNode, Sequence[BaseTool]],\n",
    "    system_prompt: Optional[str] = None,\n",
    ") -> CompiledGraph:\n",
    "    model = model.bind_tools(tools)\n",
    "    def should_continue(state: AgentState):\n",
    "        messages = state[\"messages\"]\n",
    "        last_message = messages[-1]\n",
    "        if isinstance(last_message, AIMessage) and last_message.tool_calls:\n",
    "            return \"continue\"\n",
    "        else:\n",
    "            return \"end\"\n",
    "\n",
    "    if system_prompt:\n",
    "        preprocessor = RunnableLambda(\n",
    "            lambda state: [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "        )\n",
    "    else:\n",
    "        preprocessor = RunnableLambda(lambda state: state[\"messages\"])\n",
    "\n",
    "    model_runnable = preprocessor | model\n",
    "    def call_model(state: AgentState, config: RunnableConfig):\n",
    "        response = model_runnable.invoke(state, config)\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    workflow = StateGraph(AgentState)\n",
    "    workflow.add_node(\"agent\", RunnableLambda(call_model))\n",
    "    workflow.add_node(\"tools\", ToolNode(tools))\n",
    "    workflow.set_entry_point(\"agent\")\n",
    "    workflow.add_conditional_edges(\"agent\", should_continue, {\"continue\": \"tools\", \"end\": END})\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "    return workflow.compile()\n",
    "\n",
    "# --- Agent Wrapper Class ---\n",
    "class LangGraphResponsesAgent(ResponsesAgent):\n",
    "    def __init__(self, agent: CompiledStateGraph):\n",
    "        self.agent = agent\n",
    "\n",
    "    def _responses_to_cc(self, message: dict[str, Any]) -> list[dict[str, Any]]:\n",
    "        \"\"\"Convert from a Responses API output item to ChatCompletion messages.\"\"\"\n",
    "        msg_type = message.get(\"type\")\n",
    "        if msg_type == \"function_call\":\n",
    "            return [\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"tool call\",\n",
    "                    \"tool_calls\": [\n",
    "                        {\n",
    "                            \"id\": message[\"call_id\"],\n",
    "                            \"type\": \"function\",\n",
    "                            \"function\": {\n",
    "                                \"arguments\": message[\"arguments\"],\n",
    "                                \"name\": message[\"name\"],\n",
    "                            },\n",
    "                        }\n",
    "                    ],\n",
    "                }\n",
    "            ]\n",
    "        elif msg_type == \"message\" and isinstance(message[\"content\"], list):\n",
    "            return [\n",
    "                {\"role\": message[\"role\"], \"content\": content[\"text\"]}\n",
    "                for content in message[\"content\"]\n",
    "            ]\n",
    "        elif msg_type == \"reasoning\":\n",
    "            return [{\"role\": \"assistant\", \"content\": json.dumps(message[\"summary\"])}]\n",
    "        elif msg_type == \"function_call_output\":\n",
    "            return [\n",
    "                {\n",
    "                    \"role\": \"tool\",\n",
    "                    \"content\": message[\"output\"],\n",
    "                    \"tool_call_id\": message[\"call_id\"],\n",
    "                }\n",
    "            ]\n",
    "        compatible_keys = [\"role\", \"content\", \"name\", \"tool_calls\", \"tool_call_id\"]\n",
    "        filtered = {k: v for k, v in message.items() if k in compatible_keys}\n",
    "        return [filtered] if filtered else []\n",
    "\n",
    "    def _langchain_to_responses(self, messages: list[dict[str, Any]]) -> list[dict[str, Any]]:\n",
    "        \"Convert from ChatCompletion dict to Responses output item dictionaries\"\n",
    "        for message in messages:\n",
    "            message = message.model_dump()\n",
    "            role = message[\"type\"]\n",
    "            if role == \"ai\":\n",
    "                if tool_calls := message.get(\"tool_calls\"):\n",
    "                    return [\n",
    "                        self.create_function_call_item(\n",
    "                            id=message.get(\"id\") or str(uuid4()),\n",
    "                            call_id=tool_call[\"id\"],\n",
    "                            name=tool_call[\"name\"],\n",
    "                            arguments=json.dumps(tool_call[\"args\"]),\n",
    "                        )\n",
    "                        for tool_call in tool_calls\n",
    "                    ]\n",
    "                else:\n",
    "                    return [\n",
    "                        self.create_text_output_item(\n",
    "                            text=message[\"content\"],\n",
    "                            id=message.get(\"id\") or str(uuid4()),\n",
    "                        )\n",
    "                    ]\n",
    "            elif role == \"tool\":\n",
    "                return [\n",
    "                    self.create_function_call_output_item(\n",
    "                        call_id=message[\"tool_call_id\"],\n",
    "                        output=message[\"content\"],\n",
    "                    )\n",
    "                ]\n",
    "            elif role == \"user\":\n",
    "                return [message]\n",
    "\n",
    "    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:\n",
    "        outputs = [\n",
    "            event.item\n",
    "            for event in self.predict_stream(request)\n",
    "            if event.type == \"response.output_item.done\"\n",
    "        ]\n",
    "        return ResponsesAgentResponse(output=outputs, custom_outputs=request.custom_inputs)\n",
    "\n",
    "    def predict_stream(\n",
    "        self,\n",
    "        request: ResponsesAgentRequest,\n",
    "    ) -> Generator[ResponsesAgentStreamEvent, None, None]:\n",
    "        cc_msgs = []\n",
    "        for msg in request.input:\n",
    "            cc_msgs.extend(self._responses_to_cc(msg.model_dump()))\n",
    "\n",
    "        for event in self.agent.stream({\"messages\": cc_msgs}, stream_mode=[\"updates\", \"messages\"]):\n",
    "            if event[0] == \"updates\":\n",
    "                for node_data in event[1].values():\n",
    "                    for item in self._langchain_to_responses(node_data[\"messages\"]):\n",
    "                        yield ResponsesAgentStreamEvent(type=\"response.output_item.done\", item=item)\n",
    "            elif event[0] == \"messages\":\n",
    "                try:\n",
    "                    chunk = event[1][0]\n",
    "                    if isinstance(chunk, AIMessageChunk) and (content := chunk.content):\n",
    "                        yield ResponsesAgentStreamEvent(\n",
    "                            **self.create_text_delta(delta=content, item_id=chunk.id),\n",
    "                        )\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "\n",
    "# --- Agent Initialization ---\n",
    "agent_system_prompt = \"\"\"You are a RAG chatbot working for a television network company. You will be used to help make recommendations for optimal placement of advertisements based on program scripts. For this example, you have access to movie scripts, but the intention is to air commercials. Based on the user query, query the retreiver tool to get the most relevant scripts from the movie scenes and synthesize this information, combined with the proposed advertisement into a helpful response that accurately recommends the best scene to place an advertisement. The retreiver will return required metadata as well as the similarity score.\n",
    "\n",
    "Only make a second request to the retreiver tool if the initial scenes returned are extremely poor, or have low similarity scores. Similarity scores under 0.80 should be deemed poor, if any of the requests are above 0.80, do not make an additional request. Do not make more than 2 requests to the retriever tool. Include relevant keywords in the request to the retriever tool that would be reflected in a scene that matches the user intent.\n",
    "\n",
    "The title and scene number are fields returned by the retriever tool you have access to - it will be returned to you as 'scene_number' from the vector search retreival tool, and the title will be returned as 'title'. Structure the response in the following manner, provide nothing else outside of the structure below, the structure includes the desired markdown formatting:\n",
    "\n",
    "# Movie Title: INSERT MOVIE\n",
    "# Scene Number: INSERT SCENE NUMBER\n",
    "# Scene Description: \n",
    "  Describe the scene in 1-3 sentences\n",
    "# Scene Justification \n",
    "  Provide a justification for why this scene is the best option in 2-3 sentences\n",
    "\"\"\"\n",
    "# The agent object is now a pyfunc model that can be logged.\n",
    "mlflow.langchain.autolog()\n",
    "agent = create_tool_calling_agent(llm, tools, system_prompt=agent_system_prompt)\n",
    "AGENT = LangGraphResponsesAgent(agent)\n",
    "mlflow.models.set_model(AGENT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "103faa89-36ea-49f7-b48f-145996137b5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test the agent\n",
    "\n",
    "Interact with the agent to test its output. Since this notebook called `mlflow.langchain.autolog()` you can view the trace for each step the agent takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe32d25d-5ab3-463d-a2b6-a545e588ab3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from agent import AGENT\n",
    "result = AGENT.predict({\"input\": [{\"role\": \"user\", \"content\": \"When could I insert a commercial for an alien pet food brand in a movie based underwater\"}]})\n",
    "print(result.model_dump(exclude_none=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03180f34-eca7-4230-9517-f11cb3398a03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for event in AGENT.predict_stream({\"input\": [{\"role\": \"user\", \"content\": \"Where should I place the following advertisement: This advertisement for Bricks High Quality Pet Food shows a bulldog with its tongue out standing next to a large bag of their Premium Blend teacup pig food on a grassy outdoor setting. for the following target audience: Spanish-speaking women age 18-34 primarily based in the american southwest\"}]}):\n",
    "    event.model_dump(exclude_none=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5657bea4-8fa8-43bb-9193-c394831fbc35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Log the model to MLflow\n",
    "import os\n",
    "import mlflow\n",
    "from agent import function_name, llm_endpoint, index_name\n",
    "from databricks_langchain import VectorSearchRetrieverTool\n",
    "from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint, DatabricksVectorSearchIndex\n",
    "from unitycatalog.ai.langchain.toolkit import UnityCatalogTool\n",
    "from pkg_resources import get_distribution\n",
    "\n",
    "print(f'mlflow version: {mlflow.__version__}')\n",
    "\n",
    "input_example = {\n",
    "    \"input\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"When could I insert a commercial for a light hearted basketball-themed comedy movie we want to promote for next summer?\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name='agent',\n",
    "        python_model=\"agent.py\",\n",
    "        pip_requirements=[\n",
    "            \"databricks-langchain\",\n",
    "            f\"langgraph=={get_distribution('langgraph').version}\",\n",
    "            f\"databricks-connect=={get_distribution('databricks-connect').version}\",\n",
    "        ],\n",
    "        resources=[\n",
    "            DatabricksServingEndpoint(endpoint_name=llm_endpoint),\n",
    "            DatabricksVectorSearchIndex(index_name=index_name),\n",
    "            DatabricksFunction(function_name=function_name)\n",
    "        ],\n",
    "        input_example=input_example\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Use the workspace client to retrieve information about the current user\n",
    "w = WorkspaceClient()\n",
    "user_email = w.current_user.me().display_name\n",
    "username = user_email.split(\"@\")[0]\n",
    "\n",
    "# Catalog and schema have been automatically created\n",
    "catalog_name = 'media_advertising'\n",
    "schema_name = 'contextual_advertising'\n",
    "\n",
    "# TODO: define the catalog, schema, and model name for your UC model\n",
    "model_name = \"movie_scripts_placement_agent\" # Change to a different model name if desired\n",
    "UC_MODEL_NAME = f\"{catalog_name}.{schema_name}.{model_name}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "client = mlflow.MlflowClient()\n",
    "\n",
    "CATALOG = 'media_advertising'\n",
    "SCHEMA = 'contextual_advertising'\n",
    "model_name = \"movie_scripts_placement_agent\" # Change to a different model name if desired\n",
    "UC_MODEL_NAME = f\"{CATALOG}.{SCHEMA}.{model_name}\"\n",
    "\n",
    "uc_registered_model_detail = client.get_model_version(name=UC_MODEL_NAME, version=uc_registered_model_info.version)\n",
    "print(uc_registered_model_detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "# Deploy the model to the review app and a model serving endpoint\n",
    "agents.deploy(UC_MODEL_NAME, uc_registered_model_info.version)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "/Workspace/Users/wesley.pasfield@databricks.com/AandE_workshop_April_2025/env.yaml",
    "dependencies": [
     "langchain-community",
     "langgraph==0.2.16",
     "langchain_databricks",
     "langchain",
     "langgraph-checkpoint",
     "langchain_core",
     "pydantic",
     "mlflow-skinny"
    ],
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "02_Agent_Definition",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

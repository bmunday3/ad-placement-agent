{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "569ef0a5-df1c-4996-982b-d95918bed6d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %pip install beautifulsoup4 tqdm lxml\n",
    "# dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install all dependencies from requirements.txt\n",
    "%pip install -r requirements.txt\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull Data\n",
    "\n",
    "1. Get links associated with each movie in the database\n",
    "2. Pull scripts and relevant metadata\n",
    "3. Print out errors for any movies that are not obtained properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c728e2b-df2d-46c7-9f70-99dab8a06aff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CATALOG = \"movie_scripts\" # Ex. wesley_pasfield\n",
    "SCHEMA = \"ad_placement_agent\" #Ex. aandeworkshop\n",
    "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
    "spark.sql(f\"USE SCHEMA {SCHEMA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e68c6261-b351-4aaa-8fa0-73cd09dcad3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import bs4\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "BASE_URL = \"https://imsdb.com\"\n",
    "\n",
    "def get_all_links():\n",
    "  \"\"\"\n",
    "  Fetches all movie script links from the IMSDb website.\n",
    "\n",
    "  Returns:\n",
    "  list: A list of URLs pointing to individual movie scripts.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    response = requests.get(BASE_URL + '/all-scripts.html')\n",
    "    response.raise_for_status()\n",
    "    print(response)\n",
    "    soup = bs4.BeautifulSoup(response.text, 'lxml')\n",
    "    links = soup.findAll('td', {'valign': 'top'})[-1].findAll('a')\n",
    "    return [BASE_URL + l.get('href') for l in links]\n",
    "  except requests.RequestException as e:\n",
    "    print(f\"Error fetching all links: {e}\")\n",
    "    return []\n",
    "\n",
    "def retrieve_script(url):\n",
    "  \"\"\"\n",
    "  Retrieves the script text from a given URL.\n",
    "\n",
    "  Args:\n",
    "    url (str): The URL of the movie script.\n",
    "\n",
    "  Returns:\n",
    "    str: The text content of the movie script.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = bs4.BeautifulSoup(response.text, 'lxml')\n",
    "    return soup.find('td', {'class': 'scrtext'}).find('pre').text\n",
    "  except Exception as e:\n",
    "    raise ValueError(f\"Error retrieving script from {url}: {e}\")\n",
    "\n",
    "def process_link(url):\n",
    "  \"\"\"\n",
    "  Extracts metadata and script content from a given movie script URL.\n",
    "\n",
    "  Args:\n",
    "    url (str): The URL of the movie script page.\n",
    "\n",
    "  Returns:\n",
    "    dict: A dictionary containing metadata and script content of the movie.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = bs4.BeautifulSoup(response.text, 'lxml')\n",
    "    table = soup.find('table', {'class': 'script-details'})\n",
    "    title = table.find('h1').text\n",
    "    poster = table.find('td', {'align': 'right', 'valign': 'top'}).find('img').get('src')\n",
    "\n",
    "    texts = table.find('b', string='IMSDb opinion').parent.text\n",
    "    patterns = {\n",
    "      'IMSDb_opinion': r\"IMSDb opinion\\s+(?P<opinion>.+?)\\n\",\n",
    "      'IMSDb_rating': r\"IMSDb rating\\s+(?P<rating>.+?)\\n\",\n",
    "      'average_user_rating': r\"Average user rating\\s+\\((?P<rating>[\\d.]+)(?: out of \\d+)?\",\n",
    "      'writers': r\"Writers\\s+(?P<writers>.+?)\\n\",\n",
    "      'genres': r\"Genres\\s+(?P<genres>.+?)\\n\",\n",
    "      'script_date': r\"Script Date : (?P<date>[\\w\\s]+?)\\n\",\n",
    "      'movie_release_date': r\"Movie Release Date : (?P<date>[\\w\\s]+?)\\n\",\n",
    "      'submitted_by': r\"Submitted by: (?P<submitter>\\w+)\\n\"\n",
    "    }\n",
    "    d = {}\n",
    "    for k, pattern in patterns.items():\n",
    "      match = re.search(pattern, texts)\n",
    "      if match:\n",
    "        if k in ['writers', 'genres']:\n",
    "          d[k] = re.split(r'\\s{2,}', match.group(1))\n",
    "        else:\n",
    "          d[k] = match.group(1)\n",
    "    d['title'] = title[:-len(' Script')]\n",
    "    d['poster'] = poster\n",
    "    script_url = BASE_URL + soup.find('a', href=re.compile(r'/scripts/')).get('href')\n",
    "    d['script'] = retrieve_script(script_url)\n",
    "    return d\n",
    "  except Exception as e:\n",
    "    print(f'Error!: {e}')\n",
    "    return None\n",
    "  \n",
    "def get_poster_data(poster_url: str, movie_id: str) -> list:\n",
    "    \"\"\"\n",
    "    Fetches image data from a URL and returns it along with the movie_id.\n",
    "    This function does NOT save any files to disk.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the movie poster image.\n",
    "        movie_id (str): A unique identifier for the movie.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing [movie_id, img_data_bytes] where\n",
    "              img_data_bytes is the raw binary content of the image.\n",
    "              Returns [movie_id, None] if fetching fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if poster_url == \"/images/no-poster.gif\":\n",
    "          return [movie_id, None]\n",
    "        # Fetch the image data directly as bytes\n",
    "        img_data = requests.get(poster_url, timeout=30).content # Added a timeout for robustness\n",
    "        return [movie_id, img_data]\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching poster for movie ID {movie_id} from {poster_url}: {e}\")\n",
    "        return [movie_id, None] # Return None for image data if fetching fails\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred for movie ID {movie_id} from {poster_url}: {e}\")\n",
    "        return [movie_id, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "416820cd-3aad-4f9f-9cee-880337429a59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get all links from the database\n",
    "\n",
    "links = get_all_links()\n",
    "\n",
    "# Pull in all metadata and scripts for each movie obtained\n",
    "# Print out errors - should be 1222 that pull successfully\n",
    "\n",
    "movie_data = []  \n",
    "movie_images = []\n",
    "i = 1\n",
    "for link in tqdm(links, desc=\"Processing links\"):\n",
    "  movie_result = process_link(link)\n",
    "  if movie_result:\n",
    "    movie_result['unique_movie_id'] = i\n",
    "    movie_data.append(movie_result)\n",
    "    image_result = get_poster_data(poster_url = movie_result['poster'], movie_id = movie_result['unique_movie_id'])\n",
    "    if image_result:\n",
    "      movie_images.append(image_result)\n",
    "  i= i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "820703d1-8968-4fe8-800a-455c405d5d92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Normalize Data\n",
    "\n",
    "1. Create unique identifier for each movie information \n",
    "2. Flatten out genre & writers information as they are stored as arrays\n",
    "3. Separate out the script into its own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc8e7cc1-bfed-493e-b656-9f2c9ed2d963",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "movie_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0a491ba-fd9a-4655-8e49-6650ea7131df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Pull out all keys from the obtained database\n",
    "\n",
    "all_keys = set().union(*(d.keys() for d in movie_data))\n",
    "keys = movie_data[0].keys()\n",
    "\n",
    "# Isolate the script data to be saved in a volume\n",
    "\n",
    "script_volume = [{'unique_movie_id': d['unique_movie_id'], 'script': d['script']} for d in movie_data]\n",
    "\n",
    "# Flatten out writers & genre data\n",
    "\n",
    "flattened_writers = [{'unique_movie_id': d['unique_movie_id'], 'writer': writer} for d in movie_data for writer in d['writers']]\n",
    "flattened_genres = [{'unique_movie_id': d['unique_movie_id'], 'genre': genre} for d in movie_data for genre in d['genres']]\n",
    "\n",
    "print('Flattened writers \\n')\n",
    "print(flattened_writers[0:3])\n",
    "print('Flattened genres \\n')\n",
    "print(flattened_genres[0:3])\n",
    "\n",
    "# Drop script, writer & genre columns from original data\n",
    "\n",
    "for d in movie_data:\n",
    "  del d['writers']\n",
    "  del d['genres']\n",
    "  del d['script']\n",
    "\n",
    "print('General metadata')\n",
    "print(movie_data[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7512368-32c9-4d95-b1ed-9a1d41f29a73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Save Data\n",
    "\n",
    "Below is the final datasets created. There are in the wesley_pasfield.AandEWorkshop catalog.schema\n",
    "\n",
    "1. movie_metadata\n",
    "\n",
    "```\n",
    "unique_movie_id is primary key\n",
    "\n",
    "unique_movie_id: Unique Identifier for a movie\n",
    "IMSDb_opinion: Quick summary to the movie\n",
    "IMSDb_rating: Summary rating\n",
    "average_user_rating: Average user rating\n",
    "title: Movie Title\n",
    "poster: Image associated with the poster\n",
    "```\n",
    "2. writers\n",
    "\n",
    "```\n",
    "unique_movie_id and writer together are composite primary key\n",
    "There can be multiple writers associated with each movie\n",
    "\n",
    "unique_movie_id: Unique identifier for the movie\n",
    "writer: Writer name associated with the movie\n",
    "```\n",
    "3. genres\n",
    "```\n",
    "unique_movie_id and genre together are composite primary key\n",
    "There can be multiple genres associated with each movie\n",
    "\n",
    "unique_movie_id: Unique identifier for the movie\n",
    "genre: Genre associated with the movie\n",
    "```\n",
    "4. scripts\n",
    "```\n",
    "unique_movie_id is the primary key\n",
    "\n",
    "unique_movie_id: Unique identifier for the movie\n",
    "script: Script associated with the movie\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "246d6fa6-a0b8-4294-b439-da559d8965f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, LongType, BinaryType\n",
    "\n",
    "# Convert lists to DataFrames\n",
    "writers_df = spark.createDataFrame(flattened_writers)\n",
    "genres_df = spark.createDataFrame(flattened_genres)\n",
    "movie_metadata_df = spark.createDataFrame(movie_data)\n",
    "scripts_df = spark.createDataFrame(script_volume)\n",
    "\n",
    "# Write DataFrames to tables\n",
    "writers_df.write.mode(\"overwrite\").saveAsTable(f\"{CATALOG}.{SCHEMA}.writers\")\n",
    "genres_df.write.mode(\"overwrite\").saveAsTable(f\"{CATALOG}.{SCHEMA}.genres\")\n",
    "movie_metadata_df.write.mode(\"overwrite\").saveAsTable(f\"{CATALOG}.{SCHEMA}.movie_metadata\")\n",
    "\n",
    "# Write scripts to a volume\n",
    "scripts_df.write.format(\"delta\").mode(\"overwrite\").save(f\"/Volumes/{CATALOG}/{SCHEMA}/scripts\")\n",
    "\n",
    "# Write images to a volume\n",
    "image_schema = StructType([\n",
    "    StructField(\"id\", LongType(), True),\n",
    "    StructField(\"image_data\", BinaryType(), True)\n",
    "])\n",
    "images_df = spark.createDataFrame(movie_images, schema=image_schema)\n",
    "images_df.write.format(\"delta\").mode(\"overwrite\").save(f\"/Volumes/{CATALOG}/{SCHEMA}/movie_posters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a56f0f25-d736-4b35-b5d6-7c08bab9f483",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load data to test out\n",
    "\n",
    "# Read DataFrames from tables\n",
    "writers_df = spark.table(f\"{CATALOG}.{SCHEMA}.writers\")\n",
    "genres_df = spark.table(f\"{CATALOG}.{SCHEMA}.genres\")\n",
    "movie_metadata_df = spark.table(f\"{CATALOG}.{SCHEMA}.movie_metadata\")\n",
    "\n",
    "# Read scripts from the volume\n",
    "scripts_df = spark.read.format(\"delta\").load(f\"/Volumes/{CATALOG}/{SCHEMA}/scripts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ebe88ea-8107-4ec6-b7fc-168039d22900",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"2000\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "00_Movie_Dataset_Creation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
